{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuyL3T6xtir7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from utils_2D import gaussian_process_2d, normalize, solve_allen_cahn, save_object, load_object, Net_FNN, Net_CNN, ONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2x2o-xyszDbV"
   },
   "outputs": [],
   "source": [
    "# Generate training data (x, u)\n",
    "# 2D random distribution of u \n",
    "class Data():\n",
    "    '''du/dt=-ku(x,t), -1<=x<=1\n",
    "        input u(x, t0)\n",
    "       output u(x, t1)\n",
    "    '''\n",
    "    def __init__(self, x, n_grid, length_scale, train_num, test_num):\n",
    "        \n",
    "        self.x = x\n",
    "        self.n_grid = n_grid\n",
    "        self.length_scale = length_scale\n",
    "        self.train_num = train_num\n",
    "        self.test_num = test_num\n",
    "        self.__init_data()\n",
    "        \n",
    "    def __init_data(self):\n",
    "        \n",
    "        self.X, self.u_train = self.u_data(self.train_num)\n",
    "        _, self.u_test = self.u_data(self.test_num)\n",
    "    \n",
    "\n",
    "    def u_data(self, n_samples=1):\n",
    "\n",
    "        # us - random distribution of u(x)\n",
    "        # X - corresponding locations (space coordinates) of us\n",
    "        X, us =  gaussian_process_2d(self.x, self.n_grid, n_samples, self.length_scale, u_mean=0.)\n",
    "        \n",
    "        # Normalize distribution within [-1, 1]\n",
    "        us = normalize(us)\n",
    "        us = us.reshape(-1, self.n_grid, self.n_grid)\n",
    "        us = np.expand_dims(us, axis=-1)\n",
    "        \n",
    "        return tf.constant(X, dtype=tf.float32), tf.constant(us, dtype=tf.float32)\n",
    "    \n",
    "    def x_data(self, Nx):\n",
    "\n",
    "        Xf = np.random.rand(Nx, 2)*2. - 1.0\n",
    "        Xf = tf.constant(Xf, dtype=tf.float32)\n",
    "\n",
    "        return Xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6x8tAOra28wk"
   },
   "outputs": [],
   "source": [
    "tao = 0.005 # time step\n",
    "eps = 0.25  # physical constant: length scale\n",
    "\n",
    "# 2D Solution domain\n",
    "xd = -1, 1, -1, 1\n",
    "a0, a1, b0, b1 = xd\n",
    "\n",
    "# homogenious free energy density\n",
    "Fe = lambda u: (u**2 - 1)**2/4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEaRcs0EzDbk"
   },
   "outputs": [],
   "source": [
    "n_grid = 28\n",
    "length_scale_list = [0.2, 0.5]\n",
    "train_num = 400\n",
    "test_num = 100\n",
    "data_sensor = Data(xd, n_grid, length_scale_list, train_num, test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data_sensor.u_train[1, :, :, 0], vmin=-1, vmax=1, cmap=cm.gray_r)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf = data_sensor.X\n",
    "u_train = data_sensor.u_train\n",
    "u_test = data_sensor.u_test\n",
    "\n",
    "# Get the solution for the next time step tao as the input for training\n",
    "# Boundary condition will be satisfied\n",
    "u_train = solve_allen_cahn(u_train, xd, n_grid, tao, eps)\n",
    "u_test = solve_allen_cahn(u_test, xd, n_grid, tao, eps)\n",
    "\n",
    "# Get the solution for the next time step tao as the output of the ground truth\n",
    "u_out_train = solve_allen_cahn(u_train, xd, n_grid, tao, eps)\n",
    "u_out_test = solve_allen_cahn(u_test, xd, n_grid, tao, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random u is generated in a grid of 28X28\n",
    "# We sample 14X14 points from the grid to decrease the number of input features for branch net\n",
    "n_grid_sample = 14\n",
    "n_interval = int(n_grid / n_grid_sample)\n",
    "\n",
    "u_train_p = u_train\n",
    "u_train = u_train[:,::n_interval,::n_interval,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all data as one pickle file\n",
    "# save_object([Xf, u_train, u_out_train, u_test, u_out_test], 'Data/2D_AH_N2.pkl')\n",
    "Xf, u_train, u_out_train, u_test, u_out_test = load_object('Data/2D_AH_N2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqJ7G4Ihsyu0"
   },
   "outputs": [],
   "source": [
    "n_outs = 100\n",
    "\n",
    "branch_c_1 = {\n",
    "    'filters': 32,\n",
    "    'kernels': (3, 3),\n",
    "    'strides': (1, 1),\n",
    "    'padding': 'valid',\n",
    "    'activation': None\n",
    "}\n",
    "branch_c_2 = {\n",
    "    'filters': 4,\n",
    "    'kernels': (3, 3),\n",
    "    'strides': (3, 3),\n",
    "    'padding': 'valid',\n",
    "    'activation': None\n",
    "}\n",
    "branch_c_3 = {\n",
    "    'filters': 5,\n",
    "    'kernels': (7, 7),\n",
    "    'strides': (7, 7),\n",
    "    'padding': 'valid',\n",
    "    'activation': None\n",
    "}\n",
    "\n",
    "branch_f = [{\n",
    "    'nodes': [n_outs],\n",
    "    'activation': 'relu'\n",
    "}]\n",
    " \n",
    "trunk_f = [{\n",
    "    'nodes': [100, 100],\n",
    "    'activation': 'relu'\n",
    "},\n",
    "{\n",
    "    'nodes': [n_outs],\n",
    "    'activation': 'linear'\n",
    "}]\n",
    "\n",
    "net_branch = Net_CNN([branch_c_1, branch_c_2], Net_FNN(branch_f))\n",
    "net_trunk  = Net_FNN(trunk_f)\n",
    "onet = ONet(net_trunk, net_branch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWrsZnnAKlq3",
    "outputId": "f1e395cf-a284-4e35-f379-bad29ab45db5"
   },
   "outputs": [],
   "source": [
    "onet(u_train[0:1,:,:,:], Xf, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nP2YgmsuM67J",
    "outputId": "2e8cfd05-8397-4f82-f22d-97cf04189370"
   },
   "outputs": [],
   "source": [
    "onet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_branch.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((u_train, u_train_p))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=train_num).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCY47ay_dwOQ"
   },
   "outputs": [],
   "source": [
    "def physics_informed_train_step(onet, up, Xf, up0):\n",
    "    \n",
    "    with tf.GradientTape() as g:\n",
    "\n",
    "        u, du_x, du_y = onet(up, Xf, True)\n",
    "\n",
    "        #du_x, du_y = du_x/a1, du_y/b1\n",
    "\n",
    "        ut = tf.reshape(tf.squeeze(up0), [up0.shape[0], -1]) # 4D -> 2D\n",
    "        #u0 = onet(up, data_sensor.X)\n",
    "\n",
    "        L_enegy    = tf.reduce_mean(0.5*(du_x**2 + du_y**2) + 1/eps**2*Fe(u)) * (a1-a0)*(b1-b0)/4\n",
    "        L_distance = tf.reduce_mean((ut - u)**2)/tao/2 * (a1-a0)*(b1-b0)/4\n",
    "\n",
    "        #print(ut.shape, u0.shape, du_x.shape, u.shape)\n",
    "\n",
    "        loss = L_enegy + L_distance\n",
    "        \n",
    "    grads = g.gradient(loss, onet.trainable_variables)\n",
    "    \n",
    "    optimizer.apply_gradients(zip(grads, onet.trainable_variables))\n",
    "        \n",
    "    return L_enegy, L_distance, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "# function to calulate the r2 score and mse\n",
    "# samples are 3d matrix, with the first dimension being the sample number\n",
    "def accuracy(u_pred, u_true):\n",
    "    \n",
    "    u_pred = tf.reshape(u_pred, (-1, n_grid*n_grid))\n",
    "    u_true = tf.reshape(u_true, (-1, n_grid*n_grid))\n",
    "    \n",
    "    r2 = r2_score(u_true, u_pred)\n",
    "    mse = mean_squared_error(u_true, u_pred)\n",
    "\n",
    "    # L2 relative error\n",
    "    l2_rel = tf.norm(u_true-u_pred)/tf.norm(u_true)\n",
    "    \n",
    "    return r2, l2_rel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 100\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "for epoch in range(nepochs): \n",
    "\n",
    "    for up, up0 in train_dataset:\n",
    "\n",
    "        loss_energy, loss_distance, loss = physics_informed_train_step(onet, up, Xf, up0)\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        u_test_pred = onet(u_train, Xf)\n",
    "        r2_test, mse_test = accuracy(u_test_pred, u_out_train)\n",
    "\n",
    "        print(f'Epoch Inner:{epoch+1}, Loss:{loss:.4e}, Loss_energy:{loss_energy:.4e}, Loss_distance:{loss_distance:.4e}')\n",
    "        print(f' R2:{r2_test:.4e}, MSE:{mse_test:.4e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for supervised learning\n",
    "train_dataset_sup = tf.data.Dataset.from_tensor_slices((u_train, u_out_train))\n",
    "train_dataset_sup = train_dataset_sup.shuffle(buffer_size=train_num).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQFbx1A1Ptcc"
   },
   "outputs": [],
   "source": [
    "def suppervised_train_step(onet, up, Xf, uq):\n",
    "    \n",
    "    with tf.GradientTape() as g:\n",
    "\n",
    "        #du_x, du_y = du_x/a1, du_y/b1\n",
    "\n",
    "        uq_true = tf.reshape(tf.squeeze(uq), [uq.shape[0], -1]) # 4D -> 2D\n",
    "        uq_pred = onet(up, Xf)\n",
    "\n",
    "        loss = tf.reduce_mean((uq_true - uq_pred)**2)\n",
    "        \n",
    "    grads = g.gradient(loss, onet.trainable_variables)\n",
    "    \n",
    "    optimizer.apply_gradients(zip(grads, onet.trainable_variables))\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nepochs = 1000\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "\n",
    "    for up, uq in train_dataset_sup:\n",
    "\n",
    "        loss = suppervised_train_step(onet, up, Xf, uq)\n",
    "        \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch Outer:{epoch+1}, Loss:{loss:.4e}')\n",
    "\n",
    "        u_test_pred = onet(u_train, Xf)\n",
    "        r2_test, mse_test = accuracy(u_test_pred, u_out_train)\n",
    "        print(f' R2:{r2_test:.4e}, MSE:{mse_test:.4e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Data/training_err_2D.txt', train_err, fmt='%.4e')\n",
    "np.savetxt('Data/testing_err_2D.txt', test_err, fmt='%.4e')\n",
    "np.savetxt('Data/r2_train_2D.txt', r2_train, fmt='%.4e')\n",
    "np.savetxt('Data/r2_test_2D.txt', r2_test, fmt='%.4e')\n",
    "np.savetxt('Data/run_time_2D.txt', run_time, fmt='%.4e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model weights\n",
    "#onet.save_weights('Data/onet_weights_2D_AC_Map')\n",
    "# load model weights\n",
    "# onet.load_weights('Data/onet_weights_2D_AC_Map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 19 #12, 18\n",
    "u0 = u_train[i:i+1, :, :, 0:1]\n",
    "\n",
    "fig, ax = plt.subplots(1,6, figsize=(26,4))\n",
    "ax[0].imshow(u_train_p[i, :, :, 0], vmin=-0.3, vmax=1.0, cmap=cm.gray_r)\n",
    "ax[0].axis('off')\n",
    "for i in range(5):\n",
    "    for _ in range(5):\n",
    "        u0_p = onet(u0, Xf)\n",
    "        u0_p = tf.reshape(u0_p, [1, n_grid, n_grid, 1])\n",
    "        u0 = u0_p[:, ::2, ::2, :]\n",
    "\n",
    "    im = ax[i+1].imshow(u0_p[0, :, :, 0], vmin=-1, vmax=1.0, cmap=cm.gray_r) #cmap=cm.gray_r\n",
    "    ax[i+1].axis('off')\n",
    "# add colorbar\n",
    "fig.subplots_adjust(right=0.95)\n",
    "cbar_ax = fig.add_axes([0.96, 0.12, 0.01, 0.75])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare u0_p and utn side by side at different time and export the results to animation\n",
    "i = 19\n",
    "u0 = u_train_p[i:i+1, :, :, 0:1]\n",
    "\n",
    "fig, ax = plt.subplots(1,6, figsize=(26,4))\n",
    "ax[0].imshow(u_train_p[i, :, :, 0], vmin=-0.3, vmax=1.0, cmap=cm.gray_r)\n",
    "ax[0].axis('off')\n",
    "for i in range(5):\n",
    "    for _ in range(5):\n",
    "        u0 = solve_allen_cahn(u0, xd, n_grid, tao, eps)\n",
    "        utn = tf.reshape(u0 , [n_grid, n_grid])\n",
    "    im = ax[i+1].imshow(utn, vmin=-1.0, vmax=1.0, cmap=cm.gray_r)\n",
    "    ax[i+1].axis('off')\n",
    "# add colorbar\n",
    "fig.subplots_adjust(right=0.95)\n",
    "cbar_ax = fig.add_axes([0.96, 0.12, 0.01, 0.75])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "from functools import partial\n",
    "\n",
    "# def updatefig(*args):\n",
    "def updatefig(frame_number, N):\n",
    "\n",
    "    global ut0, u0, im1, im2\n",
    "\n",
    "    for _ in range(N):\n",
    "\n",
    "        ut0 = solve_allen_cahn(ut0, x, n_grid, tao, eps)\n",
    "        utn = tf.reshape(ut0 , [n_grid, n_grid])\n",
    "\n",
    "        u0_p = onet(u0, Xf)\n",
    "        u0_p = tf.reshape(u0_p, [1, n_grid, n_grid, 1])\n",
    "        u0 = u0_p[:, ::2, ::2, :]\n",
    "\n",
    "    im1.set_array(utn)\n",
    "    im2.set_array(u0_p[0, :, :, 0])\n",
    "\n",
    "    t = frame_number*tao*N\n",
    "    \n",
    "    # update text\n",
    "    fig.texts[1].set_text(f'Time: {t:.2f}')\n",
    "\n",
    "    return im1, im2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 12 # 9 # 18\n",
    "ut0 = u_train_p[i:i+1, :, :, 0:1]\n",
    "u0 = u_train[i:i+1, :, :, 0:1]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8,4))\n",
    "\n",
    "\n",
    "im1 = ax[0].imshow(ut0[0,:,:,0], vmin=-0.3, vmax=1.0, cmap=cm.gray_r)\n",
    "im2 = ax[1].imshow(ut0[0, :, :, 0], vmin=-0.3, vmax=1.0, cmap=cm.gray_r) #cmap=cm.gray_r\n",
    "\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[0].set_title(f'Ground Truth')\n",
    "ax[1].set_title(f'Prediction')\n",
    "\n",
    "# title of the figure\n",
    "fig.suptitle(f'Allen-Cahn Equation', fontsize=16)\n",
    "# text beside the sup title\n",
    "fig.text(0.5, 0.08, f'Time: 0', ha='center', fontsize=12)\n",
    "\n",
    "fig.subplots_adjust(right=0.9)\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "fig.colorbar(im2, cax=cbar_ax)\n",
    "\n",
    "# export plot as animation\n",
    "anim = animation.FuncAnimation(fig,  partial(updatefig, N=2), frames=12, interval=500, blit=True)\n",
    "#anim.save('allen_cahn-3.gif', writer='imagemagick')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GradFlow_AllenCahn_Map.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "83a95b827912f9b758ca1097578c1db6bf4871afd3618b2b3e75696ffdc67ece"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
