{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy.sparse import diags\n",
    "\n",
    "from utils_1D import gaussian_process, sense, normalize, solve_Cahn_Hilliard, FNN, plot_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGtTM6IO7-et"
   },
   "outputs": [],
   "source": [
    "class ONet(tf.keras.Model):\n",
    "  \n",
    "  def __init__(self, trunk, branch):\n",
    "    super(ONet, self).__init__()\n",
    "    \n",
    "    self.trunk = trunk\n",
    "    self.branch = branch\n",
    "\n",
    "  def call(self, x_sensor, x, return_grad = False):\n",
    "\n",
    "    #y_trunk = self.trunk(x)\n",
    "\n",
    "    #x_sensor = np.expand_dims(x_sensor, 0)\n",
    "    u_branch = self.branch(x_sensor)\n",
    "    \n",
    "    if return_grad:\n",
    "        with tf.GradientTape(persistent=True) as g1:\n",
    "            g1.watch(x)\n",
    "            u_trunk = self.trunk(x)\n",
    "            #y_out = tf.tensordot(y_branch, y_trunk, axes=([1], [1]))\n",
    "            u = tf.unstack(u_trunk, axis=1)\n",
    "        du_x = []\n",
    "        #du_y = []\n",
    "        for us in u:\n",
    "        #u = tf.expand_dims(u, axis=-1)\n",
    "            du = tf.unstack(g1.gradient(us, x), axis=1)\n",
    "            du_x.append(du[0])\n",
    "            #du_y.append(du[1])\n",
    "        #du_x, du_y = tf.stack(du_x), tf.stack(du_y)\n",
    "        du_x = tf.stack(du_x)\n",
    "        #print(u_branch.shape, u_trunk.shape, du_x.shape)\n",
    "        u_out = tf.tensordot(u_branch, u_trunk, axes=([1], [1]))\n",
    "        du_x  = tf.tensordot(u_branch, du_x, axes=([1], [0]))\n",
    "        #du_y  = tf.tensordot(u_branch, du_y, axes=([1], [0]))\n",
    "\n",
    "        #return tf.tanh(u_out), tf.math.multiply(du_x, 1 - tf.math.multiply(tf.tanh(u_out), tf.tanh(u_out) )) \n",
    "        return u_out, du_x\n",
    "\n",
    "    else:\n",
    "        u_trunk = self.trunk(x)\n",
    "        u_out = tf.tensordot(u_branch, u_trunk, axes=([1], [1]))\n",
    "        \n",
    "        return u_out\n",
    "        #return tf.tanh(u_out)\n",
    "\n",
    "  def get_config(self):\n",
    "        return {\"trunk\": self.trunk, \"branch\": self.branch}\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(cls, config):\n",
    "      return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    '''du/dt=-ku(x,t), -1<=x<=1\n",
    "        input u(x, t0)\n",
    "       output u(x, t1)\n",
    "    '''\n",
    "    def __init__(self, x, sensor_in, sensor_out, length_scale, train_num, test_num):\n",
    "        self.x = x\n",
    "        self.sensor_in = sensor_in\n",
    "        self.sensor_out = sensor_out\n",
    "        self.length_scale = length_scale\n",
    "        self.train_num = train_num\n",
    "        self.test_num = test_num\n",
    "        self.__init_data()\n",
    "        \n",
    "    def __init_data(self):\n",
    "        \n",
    "        features = 100\n",
    "        u_train = gaussian_process(self.x, features, self.train_num, self.length_scale)\n",
    "        u_test = gaussian_process(self.x, features, self.test_num,  self.length_scale)\n",
    "\n",
    "        x0, x1 = self.x\n",
    "\n",
    "        X = np.linspace(x0, x1, num=features, dtype=np.float32)\n",
    "\n",
    "        u_train = 16*u_train*(1. - X)**2*X**2\n",
    "        u_test = 16*u_test*(1. - X)**2*X**2\n",
    "\n",
    "        u_train = self.zero_mean(u_train)\n",
    "        u_test = self.zero_mean(u_test)\n",
    "\n",
    "        u_train = normalize(u_train)\n",
    "        u_test = normalize(u_test)\n",
    "\n",
    "        self.u_train = tf.constant(u_train, dtype=tf.float32)\n",
    "        self.u_test = tf.constant(u_test, dtype=tf.float32)\n",
    "        self.X = tf.constant(np.reshape(X, [-1, 1]), dtype=tf.float32)\n",
    "\n",
    "\n",
    "    def zero_mean(self, y):\n",
    "            \n",
    "            y = np.divide(y, np.reshape(np.max(np.abs(y), 1), (-1,1)) )\n",
    "            \n",
    "            return np.subtract(y, np.reshape(np.mean(y, 1), (-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "Nx = 100\n",
    "L = 1.\n",
    "\n",
    "xd = [0., L]\n",
    "\n",
    "num_sensor_in = 100\n",
    "num_sensor_out = 20\n",
    "length_scale_list = [0.2] #0. 2\n",
    "num_train = 200\n",
    "num_test = 1000\n",
    "\n",
    "data_sensor = Data(xd, num_sensor_in, num_sensor_out, length_scale_list, num_train, num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tao = 5E-4  # time step\n",
    "eps = 0.025 # Pysical constant\n",
    "\n",
    "dx = L/(Nx-1) # spatial discretization for finite difference \n",
    "dt = 1e-6     # time step\n",
    "N = int(tao/dt)\n",
    "\n",
    "# Homogenous free energy density\n",
    "Fe = lambda u: (u**2 - 1)**2/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix to solve possion equation \n",
    "A = diags([1, -2, 1], [-1, 0, 1], (Nx, Nx)).toarray()\n",
    "A[0,0], A[-1,-1] = -1, -1\n",
    "invA = tf.constant(np.linalg.pinv(A), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_train = sense(data_sensor.u_train, num_sensor_in)\n",
    "#u_out_train = solve_Cahn_Hilliard(u_train, eps, dt, dx, N)\n",
    "\n",
    "u_test = sense(data_sensor.u_test, num_sensor_in)\n",
    "u_out_test = solve_Cahn_Hilliard(u_test, eps, dt, dx, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the time history of u at multiple time steps as the training data\n",
    "# Every 2 time steps \n",
    "u_train_temp = u_train\n",
    "u_out_temp = []\n",
    "#u_out_temp.append(u_out_train)\n",
    "\n",
    "for i in range(21):\n",
    "    u_train_temp = solve_Cahn_Hilliard(u_train_temp, eps, dt, dx, N)\n",
    "    if (i+1)%2 == 0:\n",
    "        u_train = tf.concat([u_train, u_train_temp], axis=0)\n",
    "    if (i+1)%2 == 1:\n",
    "        u_out_temp.append(u_train_temp)\n",
    "\n",
    "u_out_train = tf.concat(u_out_temp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_object([u_train, u_out_train, u_test, u_out_test], 'Data/CH-1D_10000-500.pkl')\n",
    "#u_train, u_out_train, u_test, u_out_test = load_object('Data/CH-1D_10000-500.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u initially sampled at 100 evenly spaced points\n",
    "u_train_p = u_train\n",
    "# down sample very 5 columns\n",
    "u_train = u_train[:, ::5]\n",
    "u_test = u_test[:, ::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layer_trunk = 3\n",
    "n_nodes_trunk =  100\n",
    "n_layer_branch = 2\n",
    "n_nodes_branch = 100\n",
    "num_sensor_out = 100\n",
    "Net_trunk = FNN(num_sensor_out, n_layer_trunk, n_nodes_trunk, 'relu')\n",
    "Net_branch = FNN(num_sensor_out, n_layer_branch, n_nodes_branch, 'relu')\n",
    "u_onet = ONet(Net_trunk, Net_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((u_train, u_train_p))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=num_train).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "# function to calulate the r2 score and mse\n",
    "# samples are 3d matrix, with the first dimension being the sample number\n",
    "def accuracy(u_pred, u_true):\n",
    "    \n",
    "    \n",
    "    r2 = r2_score(u_true, u_pred)\n",
    "    mse = mean_squared_error(u_true, u_pred)\n",
    "    # L2 relative error\n",
    "    rel = np.sqrt(np.sum((u_true - u_pred)**2)) / np.sqrt(np.sum(u_true**2))\n",
    "    \n",
    "    return r2, rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def physics_informed_train_step(onet, up, Xf, up0):\n",
    "    \n",
    "    with tf.GradientTape() as g:\n",
    "\n",
    "        uq, du_x = onet(up, Xf, True)\n",
    "        \n",
    "        du = uq - up0\n",
    "        df = tf.tensordot(- du * dx**2, invA, [[1], [1]])\n",
    "        \n",
    "        L_energy   = tf.reduce_mean(0.5*du_x**2 + 1./eps**2*Fe(uq)) * eps**2\n",
    "        L_distance = tf.reduce_mean( df * du ) /tao/2.\n",
    "        \n",
    "        L_mean_u = tf.reduce_mean(uq)**2\n",
    "        \n",
    "        loss = L_energy + L_distance + 1e3 * L_mean_u\n",
    "        \n",
    "\n",
    "    grads = g.gradient(loss, onet.trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(grads, onet.trainable_variables))  # + [lamda]\n",
    "        \n",
    "    return L_energy, L_distance, L_mean_u, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nepochs = 3000\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "X = np.linspace(0, 1, Nx, dtype=np.float32)\n",
    "X = tf.constant(X.reshape(-1,1), dtype=tf.float32)\n",
    " \n",
    "for epoch in range(nepochs):\n",
    "\n",
    "    for up, up0 in train_dataset:\n",
    " \n",
    "        L_energy, L_distance, L_mean_u, loss = physics_informed_train_step(u_onet, up, X, up0)\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch :{epoch+1}, Loss:{loss:.4e}, L_energy:{L_energy:.4e}, L_distance:{L_distance:.4e}, L_mean_u:{L_mean_u:.4e}')\n",
    "        #print(f'Accuracy: Train - {r2_train:.4f},  Test - {r2_test:.4f}\\n')\n",
    "        u_test_pred = u_onet(u_test, X)\n",
    "        r2_test, mse_test = accuracy(u_test_pred, u_out_test)\n",
    "        \n",
    "        print(f'Test r2 score:{r2_test:.4f}, Test mse:{mse_test:.4e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_sup = tf.data.Dataset.from_tensor_slices((u_train, u_out_train))\n",
    "train_dataset_sup = train_dataset_sup.shuffle(buffer_size=num_train).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suppervised_train_step(onet, up, Xf, uq):\n",
    "    \n",
    "    with tf.GradientTape() as g:\n",
    "\n",
    "        uq_pred= onet(up, Xf)\n",
    "        \n",
    "        loss = tf.reduce_mean((uq_pred - uq)**2)\n",
    "        \n",
    "\n",
    "    grads = g.gradient(loss, onet.trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(grads, onet.trainable_variables))  # + [lamda]\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nepochs = 1000\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.0002)\n",
    "\n",
    "X = np.linspace(0, 1, Nx, dtype=np.float32)\n",
    "X = tf.constant(X.reshape(-1,1), dtype=tf.float32)\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "\n",
    "    for up, uq in train_dataset:\n",
    "\n",
    "        loss = suppervised_train_step(u_onet, up, X, uq)\n",
    "\n",
    "    if (epoch+1) % 200 == 0:\n",
    "\n",
    "        u_test_pred = u_onet(u_train, X)\n",
    "        r2_test, mse_test = accuracy(u_test_pred, u_out_train)\n",
    "\n",
    "        print(f'Epoch :{epoch+1}, Loss:{loss:.4e}')\n",
    "        print(f'Test r2 score:{r2_test:.4f}, Test mse:{mse_test:.4e}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights only\n",
    "# u_onet.save_weights('Saved_Models/CH-1D-NN-Map-weights')\n",
    "# load weights only\n",
    "# u_onet.load_weights('Saved_Models/CH-1D-NN-Map-weights')\n",
    "# u_onet = tf.keras.models.load_model('Saved_Models/CH-1D-PI-Map', custom_objects={'ONet': ONet, 'FNN': FNN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up = np.array([np.cos(4*np.pi*x) for x in np.linspace(0., 1., 21)])\n",
    "up = tf.constant(up.reshape(1, -1)[0:,0:-1], dtype=tf.float32)\n",
    "\n",
    "uq = []\n",
    "uq.append(up)\n",
    "for i in range(200):\n",
    "    up = u_onet(up, X)\n",
    "    uq.append(up)\n",
    "    up = up[:,::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u0 = np.array([np.cos(4*np.pi*x) for x in np.linspace(0., 1., 101)])\n",
    "u0 = tf.constant(u0.reshape(1, -1)[0:,0:-1], dtype=tf.float32)\n",
    "\n",
    "u_exact = []\n",
    "u_exact.append(u0)\n",
    "\n",
    "for i in range(200):\n",
    "    u0 = solve_Cahn_Hilliard(u0, eps, dt, dx, N)\n",
    "    u_exact.append(u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xlim = [0., 1.]\n",
    "xticks = [0, 0.25, 0.5, 0.75, 1.]\n",
    "ylim = [-1.05, 1.05]\n",
    "yticks= [-1., -0.5, 0, 0.5, 1.]\n",
    "xlabel = r'$x$'\n",
    "ylabel = r'$c$'\n",
    "\n",
    "fig, ax = plot_2D(xlim=xlim, ylim=ylim, xticks=xticks, yticks=yticks, xlabel=xlabel, ylabel=ylabel)\n",
    "# ax.plot(X, u_exact[0][0], 'k', linewidth = 3, alpha=0.2, label='t = 0')\n",
    "\n",
    "for i in [1]:\n",
    "    u1 = uq[i][0]\n",
    "    u1_exact = u_exact[i][0]\n",
    "    \n",
    "    #ax.plot(X, u1, 'ro', markevery=1, markersize=6, markeredgewidth=1, markerfacecolor=[1, 0, 0, 0.5])\n",
    "    ax.plot(X, u1, 'r--', linewidth = 1.5)\n",
    "    #ax.plot(x, u1_exact, 'r--', linewidth = 3, alpha= 0.99, label = 't = ' + str(i) + r\"$\\mathit{\\tau}$ - Prediction\")\n",
    "    ax.plot(X, u1_exact, 'k', linewidth = 1.5) #,  label = 't = ' + str(i) + r\"$\\mathit{\\tau}$\")\n",
    "\n",
    "u1 = uq[3][0]\n",
    "u1_exact = u_exact[3][0]\n",
    "    \n",
    "#ax.plot(X, u1, 'ro', markevery=1, markersize=6, markeredgewidth=1, markerfacecolor=[1, 0, 0, 0.5])\n",
    "ax.plot(X, u1, 'r--', linewidth = 1.5)\n",
    "#ax.plot(x, u1_exact, 'r--', linewidth = 3, alpha= 0.99, label = 't = ' + str(i) + r\"$\\mathit{\\tau}$ - Prediction\")\n",
    "ax.plot(X, u1_exact, 'k', linewidth = 1.5) #,  label = 't = ' + str(i) + r\"$\\mathit{\\tau}$\")\n",
    "\n",
    "#ax.legend(fontsize='large', bbox_to_anchor=(0.88, 0.95))\n",
    "\n",
    "#plt.savefig('CH_1D_Map-1.png', dpi=300, transparent=True)\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GradientFlow_1D_Map.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "83a95b827912f9b758ca1097578c1db6bf4871afd3618b2b3e75696ffdc67ece"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
